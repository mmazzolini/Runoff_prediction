{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "162c0260",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b30cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from create_daily_csv import readsnow_in_shp_db, xarray2df, readnetcdf_in_shp_db\n",
    "from create_daily_csv import spatial_stats_daily_input\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plot\n",
    "import xarray as xr\n",
    "import datetime\n",
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import load\n",
    "from base_f import create_it_matrix\n",
    "from db_insert import insert, insert_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d72b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LIST=['ADO_DSC_CH03_0075',\n",
    "     'ADO_DSC_AT31_0254',\n",
    "     'ADO_DSC_ITC1_0072',\n",
    "     'ADO_DSC_ITC1_0020',\n",
    "     'ADO_DSC_CH07_0147',\n",
    "     'ADO_DSC_AT31_0206',\n",
    "     'ADO_DSC_ITH1_0012',\n",
    "     'ADO_DSC_AT12_0280',\n",
    "     'ADO_DSC_CH07_0100',\n",
    "     'ADO_DSC_CH05_0201',\n",
    "     'ADO_DSC_SI03_0148',\n",
    "     'ADO_DSC_ITC1_0037',\n",
    "     'ADO_DSC_FRK2_0042',\n",
    "     'ADO_DSC_CH04_0011',\n",
    "     'ADO_DSC_ITH2_0035',\n",
    "     'ADO_DSC_SI03_0033',\n",
    "     'ADO_DSC_FRK2_0041',\n",
    "     'ADO_DSC_ITH5_0006']\n",
    "\n",
    "t_unit=10\n",
    "\n",
    "era5_fileName_t=  'Z:\\ADO\\ZAMG\\downscaled_archive\\\\2m_temperature-19790101_20201231-eusalp-era5_qm.nc'\n",
    "era5_fileName_e = 'Z:\\ADO\\ZAMG\\downscaled_archive\\\\potential_evapotranspiration-19790101_20201231-eusalp-qm_era5.nc'\n",
    "era5_fileName_p = 'Z:\\ADO\\ZAMG\\downscaled_archive\\\\total_precipitation-19790101_20201231-eusalp-qm_era5.nc'\n",
    "era5_foldName_s = 'Z:\\ADO\\ZAMG\\SNOWGRID\\\\'\n",
    "# mask file needed to exclude pixels on the glaciers.\n",
    "mask_file=r'C:\\Users\\mmazzolini\\OneDrive - Scientific Network South Tyrol\\era5\\SNOWGRID\\\\snowgrid_masks.nc'\n",
    "\n",
    "path = r'C:\\Users\\mmazzolini\\OneDrive - Scientific Network South Tyrol\\Documents\\conda\\Runoff_prediction\\model_predict\\climatology\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f907293b",
   "metadata": {},
   "source": [
    "import sys, importlib\n",
    "importlib.reload(sys.modules['create_daily_csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d00868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    conn = psycopg2.connect(host=\"10.8.244.31\",\n",
    "                       database=\"climate_data\",\n",
    "                       user=\"ado_admin\",\n",
    "                       password=\"oda347hydro\",\n",
    "                       port=5432)\n",
    "                       \n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # get the metadata\n",
    "    query = f\"\"\"\n",
    "            SELECT \"id_station\", MAX(\"date\") FROM \"ML_discharge\".\"mod_disc\" \n",
    "            GROUP BY \"id_station\"    \n",
    "            \"\"\"\n",
    "    df = pd.read_sql_query(query,conn)\n",
    "    \n",
    "    # close the connection when finished\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "    df.index=df.id_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188c643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for STAT_CODE in LIST:\n",
    "\n",
    "\n",
    "    t2m = readnetcdf_in_shp_db(era5_fileName_t,STAT_CODE ,plot=False,res=5500)['t2m']\n",
    "    \n",
    "    #select dates\n",
    "    last_mod_date=np.datetime64(df.loc[STAT_CODE][1])\n",
    "    last_data_date=np.datetime64(np.array(t2m.time[-1]),'D')\n",
    "    \n",
    "    if  (last_mod_date <= last_data_date):\n",
    "\n",
    "\n",
    "        t2m = t2m.sel(time=slice(last_mod_date - np.timedelta64(365,'D'),last_data_date))\n",
    "        t2m = xarray2df(t2m.resample(time='1d').sum(skipna=False), 'T','t2m')\n",
    "\n",
    "        ### ERA5 total precipitation\n",
    "\n",
    "        #CLIP TO THE SHAPEFILE\n",
    "        tp = readnetcdf_in_shp_db(era5_fileName_p,STAT_CODE ,plot=False,res=5500)['tp']\n",
    "        tp = tp.sel(time=slice(last_mod_date - np.timedelta64(365,'D'),last_data_date))\n",
    "        tp = xarray2df(tp.resample(time='1d').sum(skipna=False), 'P','tp')\n",
    "\n",
    "\n",
    "        ### ERA5 evapotranspiration\n",
    "\n",
    "        #CLIP TO THE SHAPEFILE\n",
    "        pet = readnetcdf_in_shp_db(era5_fileName_e,STAT_CODE ,plot=False,res=5500)['pet']\n",
    "        pet = pet.sel(time=slice(last_mod_date - np.timedelta64(365,'D'),last_data_date))\n",
    "        pet = xarray2df(pet.resample(time='1d').sum(skipna=False), 'E','pet')\n",
    "\n",
    "\n",
    "        ### ERA5 SNOW VARIABLES\n",
    "\n",
    "        #CLIP TO THE SHAPEFILE\n",
    "        s = readsnow_in_shp_db(era5_foldName_s,mask_file,STAT_CODE ,plot=False,res=5500)['swe_tot']\n",
    "        s = s.sel(time=slice(last_mod_date - np.timedelta64(365,'D'),last_data_date))\n",
    "        s = xarray2df(s.resample(time='1d').sum(skipna=False), 'S','swe_tot')\n",
    "\n",
    "        #CONCATENATE THE VARIABLES\n",
    "        daily_input = pd.concat([t2m, s, tp, pet], axis=1, join='inner')\n",
    "        daily_input_stat = spatial_stats_daily_input(daily_input)\n",
    "\n",
    "        #add data to the daily_input_stat dataframe\n",
    "        n=daily_input_stat.shape[1]\n",
    "\n",
    "        #add 20 rows to the daily_input_stat dataframe\n",
    "        for i in range(1,21):\n",
    "            daily_input_stat.loc[last_data_date+np.timedelta64(i,'D')]=np.repeat(0,n)        \n",
    "        \n",
    "        daily_input_stat['Q']=0\n",
    "\n",
    "        in_matrix=create_it_matrix(daily_input_stat,36,10)\n",
    "\n",
    "        in_matrix.drop(columns='Q',inplace=True)\n",
    "\n",
    "        #read the climatology on the saved csv\n",
    "        daily_clim = pd.read_csv(path + STAT_CODE + '.csv')     \n",
    "        \n",
    "        #create a in_matrix for predictions, with the +10days and +20days\n",
    "        in_matrix_pred=pd.DataFrame(data=None)\n",
    "        pred_date=last_data_date + np.timedelta64(t_unit,'D')\n",
    "        pred_date_2=last_data_date + np.timedelta64(2*t_unit,'D')\n",
    "        \n",
    "        #fill it with the same in_matrix values\n",
    "        in_matrix_pred[pred_date] = in_matrix.loc[pred_date]\n",
    "        in_matrix_pred[pred_date_2] = in_matrix.loc[pred_date_2]\n",
    "        in_matrix_pred=in_matrix_pred.transpose()\n",
    "\n",
    "        #and the last 20 to 10th days (names ending with _-1)\n",
    "        lt=1\n",
    "        \n",
    "        #select the destination and source columns\n",
    "        change_dest = [c for c in in_matrix_pred.columns if c.split('_')[1] == str(-lt + 1)]\n",
    "        change_source = [c.split('_')[0] for c in change_dest]\n",
    "        \n",
    "        #update for the first prediction date (+10)\n",
    "        pred_dayofyear=in_matrix_pred.index[0].dayofyear\n",
    "        in_matrix_pred.loc[in_matrix_pred.index[0], change_dest]=daily_clim.loc[pred_dayofyear][change_source].values\n",
    "        #### substitute the data for the columns representing the last 10 days (names ending with _0) \n",
    "\n",
    "        #update for the first prediction date (+20)\n",
    "        pred_dayofyear=in_matrix_pred.index[1].dayofyear\n",
    "        in_matrix_pred.loc[in_matrix_pred.index[1], change_dest]=daily_clim.loc[pred_dayofyear][change_source].values\n",
    "\n",
    "        \n",
    "        #and the last -20 to -10 days (names ending with _-1) \n",
    "        lt=lt+1\n",
    "        \n",
    "        #select the destination and source columns\n",
    "        change_dest = [c for c in in_matrix_pred.columns if c.split('_')[1] == str(-lt + 1)]\n",
    "        change_source = [c.split('_')[0] for c in change_dest]\n",
    "\n",
    "        #(this time only for the 20days prediction.)\n",
    "        pred_dayofyear=in_matrix_pred.index[0].dayofyear\n",
    "        in_matrix_pred.loc[in_matrix_pred.index[1], change_dest]=daily_clim.loc[pred_dayofyear][change_source].values\n",
    "\n",
    "            \n",
    "        \n",
    "        #select the the input data from in_matrix\n",
    "        in_matrix = in_matrix[str((last_mod_date).astype('datetime64[D]')):str(last_data_date.astype('datetime64[D]'))]\n",
    "\n",
    "\n",
    "        #load the model\n",
    "        fld=r'C:\\Users\\mmazzolini\\OneDrive - Scientific Network South Tyrol\\Documents\\conda\\Runoff_prediction\\model_train\\models\\\\'\n",
    "        model=load(fld+STAT_CODE+'.joblib')\n",
    "\n",
    "        #predict the discharge and add ancillary information\n",
    "\n",
    "        data=model.predict(in_matrix)\n",
    "\n",
    "        discharge = pd.DataFrame(data=data ,index=in_matrix.index ,columns=['prediction'])\n",
    "\n",
    "        discharge['meas_disch_presence'] = False\n",
    "\n",
    "        #insert(STAT_CODE , discharge.iloc[1:])\n",
    "        \n",
    "        # now give the in_matrix_pred to the model\n",
    "        data_pred=(model.predict(in_matrix_pred))\n",
    "        results=pd.DataFrame(data=data_pred.reshape(1,-1), index=[last_data_date], columns=['10','20'])\n",
    "        \n",
    "        #insert the prediction in the database.\n",
    "        #insert_pred(STAT_CODE,results)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3bdd4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>747.42198</td>\n",
       "      <td>758.713897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   10          20\n",
       "2020-12-31  747.42198  758.713897"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "405b10d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>meas_disch_presence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>720.185483</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            prediction  meas_disch_presence\n",
       "time                                       \n",
       "2020-12-31  720.185483                False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cfd467",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11459c2b",
   "metadata": {},
   "source": [
    "with open('log.csv','a') as fd:\n",
    "    fd.write(str(last_data_date)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513c8ad3",
   "metadata": {},
   "source": [
    "    conn = psycopg2.connect(host=\"10.8.244.31\",\n",
    "                       database=\"climate_data\",\n",
    "                       user=\"ado_admin\",\n",
    "                       password=\"oda347hydro\",\n",
    "                       port=5432)\n",
    "                       \n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # get the metadata\n",
    "    query = f\"\"\"\n",
    "            DELETE FROM \"ML_discharge\".\"mod_disc\" WHERE \"meas_disch_presence\" = FALSE;    \n",
    "            \"\"\"\n",
    "    cur.execute(query)\n",
    "        \n",
    "    conn.commit()    \n",
    "    # close the connection when finished\n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2347c751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21ce9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

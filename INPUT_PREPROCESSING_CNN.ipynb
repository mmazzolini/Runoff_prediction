{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3a39119",
   "metadata": {},
   "source": [
    "### CREATE DAILY INPUT FOR THE CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "889e3048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_daily_csv import interpolate_df,readnetcdf_in_shp,xarray2df,check_data_gap,readnetcdf_in_shp_db,get_discharge_from_DB\n",
    "from create_daily_csv import spatial_stats_daily_input\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plot\n",
    "import xarray as xr\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6df83ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ADO SELECTED GAUGING STATIONS #####\n",
    "\n",
    "### LARGE ALPINE RIVERS ###\n",
    "\n",
    "STAT_CODE = 'ADO_DSC_ITC1_0020' # CASALE MONFERRATO PO\n",
    "STAT_CODE = 'ADO_DSC_ITC1_0037' #PO SANT'ANTONIO\n",
    "\n",
    "STAT_CODE = 'ADO_DSC_FRK2_0042'  #rhone viviers or valens? maybe better viviers\n",
    "STAT_CODE = 'ADO_DSC_FRK2_0040' #RHONE VALENCE\n",
    "\n",
    "STAT_CODE = 'ADO_DSC_AT12_0280'  #donau kienstock\n",
    "\n",
    "STAT_CODE = 'ADO_DSC_CH03_0075'  #rheine basel\n",
    "\n",
    "STAT_CODE = 'ADO_DSC_ITH2_0035'  #adige vo destro\n",
    "STAT_CODE = 'ADO_DSC_ITH1_0012' #adige_bronzolo\n",
    "\n",
    "### ADO CASE STUDIES ###\n",
    "\n",
    "STAT_CODE = 'ADO_DSC_ITC1_0072' # orco_SAN BENIGNO\n",
    "#STAT_CODE = 'ADO_DSC_ITC1_0060' # orco_basin -> PONT SOANA\n",
    "\n",
    "STAT_CODE = 'ADO_DSC_CH04_0011'  #THURGAU_ANDELFINGEN (ALL THE REGION, BUT OUTSIDE THE ADMINISTRATIVE LIMIT)\n",
    "STAT_CODE = 'ADO_DSC_CH05_0201' #THURGAU Halden (MUCH SMALLER)\n",
    "\n",
    "STAT_CODE = 'ADO_DSC_CH07_0006' #ticino bellinzona (larger)\n",
    "STAT_CODE = 'ADO_DSC_CH07_0147' #ticino pollegio campagna (solo da 86)\n",
    "STAT_CODE = 'ADO_DSC_CH07_0100' #locarno soldurno.(solo da 86+ bilanci tornano poco)\n",
    "\n",
    "STAT_CODE = 'ADO_DSC_AT31_0254' #upper-austria traun-wels\n",
    "STAT_CODE = 'ADO_DSC_AT31_0206' #UA traun-lambach\n",
    "\n",
    "STAT_CODE = 'ADO_DSC_FRK2_0041'  #DROME SAILLANS\n",
    "\n",
    "STAT_CODE = 'ADO_DSC_SI03_0148' #DRAVINJA VIDEM (SLIGHTLY WRONG CATCHMENT AREA.)(ONLY PART OF THE STUDY AREA)(ONLY FROM 2001)\n",
    "#STAT_CODE = 'ADO_DSC_SI03_0117' #DRAVA PTUJ --NODATA\n",
    "STAT_CODE = 'ADO_DSC_SI03_0033' #DRAVA DRAVOGRAD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff9323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST = ['ADO_DSC_ITC1_0020','ADO_DSC_ITC1_0037','ADO_DSC_FRK2_0042',\n",
    "        'ADO_DSC_AT12_0280','ADO_DSC_CH03_0075', 'ADO_DSC_ITH2_0035',\n",
    "        'ADO_DSC_ITC1_0072','ADO_DSC_CH04_0011','ADO_DSC_CH07_0006',\n",
    "        'ADO_DSC_CH07_0147','ADO_DSC_AT31_0254','ADO_DSC_FRK2_0041',\n",
    "        'ADO_DSC_SI03_0148','ADO_DSC_SI03_0033','ADO_DSC_ITH1_0012',\n",
    "        'ADO_DSC_CH05_0201','ADO_DSC_CH07_0100','ADO_DSC_AT31_0206']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe6c0f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_fileName_t=  r'C:\\Users\\mmazzolini\\OneDrive - Scientific Network South Tyrol\\era5\\2m_temperature-19790101_20181231-eusalp-qm_era5.nc'\n",
    "era5_fileName_p = r'C:\\Users\\mmazzolini\\OneDrive - Scientific Network South Tyrol\\era5\\total_precipitation-19790101_20181231-eusalp-qm_era5.nc'\n",
    "era5_fileName_e = r'C:\\Users\\mmazzolini\\OneDrive - Scientific Network South Tyrol\\era5\\potential_evapotranspiration-19790101_20181231-eusalp-qm_era5.nc'\n",
    "era5_fileName_s = r'C:\\Users\\mmazzolini\\OneDrive - Scientific Network South Tyrol\\era5\\SNOWGRID\\ado-snowgrid.nc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f93e238",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "for STAT_CODE in LIST:\n",
    "    \n",
    "   \n",
    "    ### ERA5 temperature\n",
    "\n",
    "    #CLIP TO THE SHAPEFILE\n",
    "    t2m = readnetcdf_in_shp_db(era5_fileName_t,STAT_CODE ,plot=False,res=5500)['t2m']\n",
    "    t2m=t2m.assign_coords(time=t2m[\"time.date\"])\n",
    "\n",
    "    index = pd.MultiIndex.from_product([t2m.y.values, t2m.x.values, ['T']],names=['y','x','var'])\n",
    "    reshaped = t2m.values.reshape((t2m.values.shape[0],t2m.values.shape[1]*t2m.values.shape[2]))\n",
    "\n",
    "    T = pd.DataFrame(reshaped, index=t2m.time.values,columns=index)\n",
    "\n",
    "\n",
    "    ### ERA5 total precipitation\n",
    "\n",
    "    #CLIP TO THE SHAPEFILE\n",
    "    tp = readnetcdf_in_shp_db(era5_fileName_p,STAT_CODE ,plot=False,res=5500)['tp']\n",
    "    tp=tp.assign_coords(time=tp[\"time.date\"])\n",
    "\n",
    "    index = pd.MultiIndex.from_product([tp.y.values,tp.x.values,['P']],names=['y','x','var'])\n",
    "    reshaped = tp.values.reshape((tp.values.shape[0],tp.values.shape[1]*tp.values.shape[2]))\n",
    "\n",
    "    P = pd.DataFrame(reshaped, index=tp.time.values, columns=index)\n",
    "    \n",
    "    ### ERA5 evapotranspiration\n",
    "\n",
    "    #CLIP TO THE SHAPEFILE\n",
    "    pet = readnetcdf_in_shp_db(era5_fileName_e,STAT_CODE ,plot=False,res=5500)['pet']\n",
    "    pet=pet.assign_coords(time=pet[\"time.date\"])\n",
    "\n",
    "    index = pd.MultiIndex.from_product([pet.y.values, pet.x.values, ['E']],names=['y','x','var'])\n",
    "    reshaped = pet.values.reshape((pet.values.shape[0],pet.values.shape[1]*pet.values.shape[2]))\n",
    "\n",
    "    E = pd.DataFrame(reshaped, index=pet.time.values,columns=index)\n",
    "  \n",
    "    ### ERA5 SNOW VARIABLES\n",
    "\n",
    "    #CLIP TO THE SHAPEFILE\n",
    "    s = readnetcdf_in_shp_db(era5_fileName_s,STAT_CODE ,plot=False,res=5500)['swe_tot']\n",
    "    s=s.assign_coords(time=s[\"time.date\"])\n",
    "\n",
    "    index = pd.MultiIndex.from_product([s.y.values,s.x.values,['S']],names=['y','x','var'])\n",
    "    reshaped = s.values.reshape((s.values.shape[0],s.values.shape[1]*s.values.shape[2]))\n",
    "\n",
    "    S = pd.DataFrame(reshaped, index=s.time.values,columns=index)\n",
    "    S[S < 0] = np.NaN    \n",
    "    \n",
    "    \n",
    "    #CONCATENATE THE VARIABLES\n",
    "    daily_input = pd.concat([T, P, E, S],axis=1,join='inner')    \n",
    "    daily_input.index=pd.to_datetime(daily_input.index)\n",
    "\n",
    "    #DEFINE THE PATH AND FILENAME\n",
    "    catchment_name = STAT_CODE + '.csv'\n",
    "    path=r'C:\\Users\\mmazzolini\\OneDrive - Scientific Network South Tyrol\\Documents\\conda\\daily_input_cube\\\\'+catchment_name\n",
    "    \n",
    "    #save into a csv file.\n",
    "    # if file does not exist write\n",
    "    if not os.path.isfile(path):\n",
    "       daily_input.to_csv(path)\n",
    "    else: # else print the problem\n",
    "       print('file already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92c235e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "for STAT_CODE in LIST:\n",
    "    discharge=get_discharge_from_DB(STAT_CODE)\n",
    "    discharge = discharge.rename(columns={'discharge_m3_s': 'Q'})\n",
    "\n",
    "    discharge = discharge[discharge.index > (np.datetime64('1979-12-31'))]  \n",
    "    \n",
    "    # ADD A YEAR OF NO DATA BEFORE THE 1ST COMMON DATE (BTW ERA5 AND DISCHARGE DATA)\n",
    "    \n",
    "    first_date=(max(np.datetime64(\"1980-01-01\"),discharge.index[0]))\n",
    "    idx=pd.date_range(first_date-np.timedelta64(366,'D'),first_date-np.timedelta64(1,'D'))\n",
    "    a=pd.DataFrame(np.repeat(np.nan,366),index=idx,columns=['Q'])\n",
    "    discharge=pd.concat((a,discharge),axis=0)\n",
    "\n",
    "    \n",
    "    #DEFINE THE PATH AND FILENAME\n",
    "    catchment_name = STAT_CODE + '.csv'\n",
    "    path=r'C:\\Users\\mmazzolini\\OneDrive - Scientific Network South Tyrol\\Documents\\conda\\input_discharge\\\\'+catchment_name\n",
    "    \n",
    "    #save into a csv file.\n",
    "    # if file does not exist write\n",
    "    if not os.path.isfile(path):\n",
    "       discharge.to_csv(path)\n",
    "    else: # else print the problem\n",
    "       print('file already exists')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e159fd",
   "metadata": {},
   "source": [
    "Input:\n",
    "- the measured runoff at the gauging station,\n",
    "- the catchment area of the gauging station,\n",
    "- the ERA5 datasets for Potential Evapotranspiration, Temperature and Precipitation.\n",
    "\n",
    "Output:\n",
    "    - a .csv file is saved in conda/daily_input folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dff5df",
   "metadata": {},
   "source": [
    "import sys, importlib\n",
    "importlib.reload(sys.modules['sf_runoff'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
